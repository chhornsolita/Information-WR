{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e807049",
   "metadata": {},
   "source": [
    "# Word2Vec Analysis with NLTK Brown Corpus\n",
    "\n",
    "This notebook demonstrates the training and analysis of Word2Vec embeddings using the NLTK Brown corpus. The steps include preprocessing text data, training the model, and visualizing the embeddings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27fa3433",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'#pip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# Install Required Libraries\n",
    "!#pip install gensim nltk scikit-learn plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e293da4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to C:\\Users\\ASUS/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download NLTK Brown Corpus\n",
    "import nltk\n",
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c9ec858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 57340\n",
      "First sentence: ['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.']\n"
     ]
    }
   ],
   "source": [
    "# Load Brown Sentences\n",
    "from nltk.corpus import brown\n",
    "brown_sentences = brown.sents()\n",
    "print(f\"Number of sentences: {len(brown_sentences)}\")\n",
    "print(f\"First sentence: {brown_sentences[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0887ab21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of processed sentences: 56833\n",
      "First processed sentence: ['the', 'fulton', 'county', 'grand', 'jury', 'said', 'friday', 'an', 'investigation', 'of', 'atlanta', 's', 'recent', 'primary', 'election', 'produced', 'no', 'evidence', 'that', 'any', 'irregularities', 'took', 'place']\n"
     ]
    }
   ],
   "source": [
    "# Preprocess Text Data\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "def preprocess_sentences(sentences):\n",
    "    processed = []\n",
    "    for sentence in sentences:\n",
    "        sentence = word_tokenize(' '.join(sentence).lower())\n",
    "        sentence = [re.sub(r'[^a-z]', '', word) for word in sentence]\n",
    "        sentence = [word for word in sentence if word]\n",
    "        if sentence:\n",
    "            processed.append(sentence)\n",
    "    return processed\n",
    "processed_sentences = preprocess_sentences(brown_sentences)\n",
    "print(f\"Number of processed sentences: {len(processed_sentences)}\")\n",
    "print(f\"First processed sentence: {processed_sentences[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b264f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec model training complete.\n"
     ]
    }
   ],
   "source": [
    "# Train Word2Vec Model\n",
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(\n",
    "    sentences=processed_sentences,\n",
    "    vector_size=100,\n",
    "    window=5,\n",
    "    min_count=5,\n",
    "    sg=1,\n",
    "    epochs=10\n",
    "    )\n",
    "print(\"Word2Vec model training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b5df208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector for 'king' (first 10 values): [ 0.11880429 -0.1317661  -0.02480275  0.4487808  -0.16028818 -0.28191662\n",
      "  0.2379029   0.9176345  -0.17331335 -0.07205094]\n"
     ]
    }
   ],
   "source": [
    "# Print Vector for 'king'\n",
    "if 'king' in model.wv:\n",
    "    king_vector = model.wv['king']\n",
    "    print(\"Vector for 'king' (first 10 values):\", king_vector[:10])\n",
    "else:\n",
    "    print(\"'king' is not in the vocabulary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4701967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 most similar words to 'woman':\n",
      "girl: 0.8073\n",
      "lady: 0.7150\n",
      "lonely: 0.7076\n",
      "boy: 0.6985\n",
      "lean: 0.6884\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Show 5 Most Similar Words to \"woman\"\n",
    "if \"woman\" in model.wv:\n",
    "    similar_words = model.wv.most_similar(\"woman\", topn=5)\n",
    "    print(\"5 most similar words to 'woman':\")\n",
    "    for word, similarity in similar_words:\n",
    "        print(f\"{word}: {similarity:.4f}\")\n",
    "else:\n",
    "    print(\"'woman' is not in the vocabulary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a27634b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of the analogy 'king - man + woman': ('szold', 0.6922566890716553)\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Perform Analogy: king - man + woman\n",
    "if all(word in model.wv for word in [\"king\", \"man\", \"woman\"]):\n",
    "    analogy_result = model.wv.most_similar(positive=[\"king\", \"woman\"], negative=[\"man\"], topn=1)\n",
    "    print(\"Result of the analogy 'king - man + woman':\", analogy_result[0])\n",
    "else:\n",
    "    print(\"One or more words are not in the vocabulary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3534ba20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 most similar words to 'woman':\n",
      "girl: 0.8073\n",
      "lady: 0.7150\n",
      "lonely: 0.7076\n",
      "boy: 0.6985\n",
      "lean: 0.6884\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Show 5 Most Similar Words to \"woman\"\n",
    "if \"woman\" in model.wv:\n",
    "    similar_words = model.wv.most_similar(\"woman\", topn=5)\n",
    "    print(\"5 most similar words to 'woman':\")\n",
    "    for word, similarity in similar_words:\n",
    "        print(f\"{word}: {similarity:.4f}\")\n",
    "else:\n",
    "    print(\"'woman' is not in the vocabulary.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
